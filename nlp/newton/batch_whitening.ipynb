{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Whitening Layer\n",
    "The purpose of this notebook is to implement the batch whitening layer.   \n",
    "The implementation is inspired by the implementation of BatchNorm layer from [this reference](https://d2l.ai/chapter_convolutional-modern/batch-norm.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device to use: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print(\"Device to use:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Whitening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_orthonorm(X, gamma, beta, running_mean=None, running_cov=None, eps=1e-5, momentum=0.1):\n",
    "    # Use is_grad_enabled to determine whether we are in training mode\n",
    "    assert len(X.shape) in (2, 4)\n",
    "    n_features = X.shape[1]\n",
    "\n",
    "    if len(X.shape) == 2:\n",
    "        # When using a fully connected layer, calculate the mean and\n",
    "        # variance on the feature dimension\n",
    "        shape = (1, n_features)\n",
    "        mean = X.mean(dim=0)\n",
    "        cov = torch.cov(X.T,correction=0)        \n",
    "        # var = ((X - mean) ** 2).mean(dim=0)\n",
    "    else:\n",
    "        # When using a two-dimensional convolutional layer, calculate the\n",
    "        # mean and covariance on the channel dimension (axis=1). Here we\n",
    "        # need to maintain the shape of X, so that the broadcasting\n",
    "        # operation can be carried out later\n",
    "        shape = (1, n_features, 1, 1)\n",
    "        mean = X.mean(dim=(0, 2, 3))\n",
    "        Xtmp = X.view(X.shape[0],X.shape[1],-1)\n",
    "        Xtmp = Xtmp.permute(1,0,2).reshape(X.shape[1],-1)\n",
    "        cov = torch.cov(Xtmp,correction=0) \n",
    "        # var = ((X - mean) ** 2).mean(dim=(0, 2, 3), keepdim=True)\n",
    "    # In training mode, the current mean and variance are used\n",
    "    # Update the mean and variance using moving average\n",
    "    if torch.is_grad_enabled():\n",
    "        running_mean = (1.0 - momentum) * running_mean + momentum * mean\n",
    "        running_cov = (1.0 - momentum) * running_cov + momentum * cov\n",
    "        L = torch.linalg.cholesky(cov + eps*torch.eye(n_features))\n",
    "        if len(X.shape) == 2:\n",
    "            X_hat = (X-mean.view(1,n_features)).T\n",
    "            Y = torch.linalg.solve_triangular(L,X_hat,upper=False).T\n",
    "        else:\n",
    "            X_hat = X-mean.view(1,n_features,1,1)\n",
    "            X_hat = X_hat.permute(1,0,2,3).reshape(X.shape[1],-1)\n",
    "            Y = torch.linalg.solve_triangular(L,X_hat,upper=False).reshape(X.shape[1],X.shape[0],X.shape[2],X.shape[3]).permute(1,0,2,3)\n",
    "    else:\n",
    "        L = torch.linalg.cholesky(running_cov + eps*torch.eye(n_features))\n",
    "        if len(X.shape) == 2:\n",
    "            X_hat = (X-running_mean.view(1,n_features)).T\n",
    "            Y = torch.linalg.solve_triangular(L,X_hat,upper=False).T\n",
    "        else:\n",
    "            X_hat = X-running_mean.view(1,n_features,1,1)\n",
    "            X_hat = X_hat.permute(1,0,2,3).reshape(X.shape[1],-1)\n",
    "            Y = torch.linalg.solve_triangular(L,X_hat,upper=False).reshape(X.shape[1],X.shape[0],X.shape[2],X.shape[3]).permute(1,0,2,3)\n",
    "    # Y = gamma.view(shape) * Y + beta.view(shape)  # Scale and shift\n",
    "    return Y, running_mean.data, running_cov.data\n",
    "\n",
    "\n",
    "class BatchWhitening(nn.Module):\n",
    "    # num_features: the number of outputs for a fully connected layer or the\n",
    "    # number of output channels for a convolutional layer. num_dims: 2 for a\n",
    "    # fully connected layer and 4 for a convolutional layer\n",
    "    def __init__(self, num_features,momentum=0.1):\n",
    "        super().__init__()\n",
    "        # The scale parameter and the shift parameter (model parameters) are\n",
    "        # initialized to 1 and 0, respectively\n",
    "        self.momentum = momentum\n",
    "        self.gamma = nn.Parameter(torch.ones(num_features))\n",
    "        self.beta = nn.Parameter(torch.zeros(num_features))\n",
    "        # The variables that are not model parameters are initialized to 0 and 1\n",
    "        self.register_buffer('running_mean', torch.zeros(num_features))\n",
    "        self.register_buffer('running_cov', torch.eye(num_features))\n",
    "\n",
    "    def forward(self, X):\n",
    "        # If X is not on the main memory, copy moving_mean and moving_var to\n",
    "        # the device where X is located\n",
    "        if self.running_mean.device != X.device:\n",
    "            self.running_mean = self.running_mean.to(X.device)\n",
    "            self.running_cov = self.running_cov.to(X.device)\n",
    "        # Save the updated running_mean and moving_var\n",
    "        # Y, self.running_mean, self.running_var = batch_orthonorm(\n",
    "        #     X, self.gamma, self.beta, self.running_mean,\n",
    "        #     self.running_cov, eps=1e-5, momentum=0.1)\n",
    "        Y, self.running_mean, self.running_cov = batch_orthonorm(\n",
    "            X, self.gamma, self.beta, self.running_mean,\n",
    "            self.running_cov, eps=1e-5, momentum=self.momentum)\n",
    "\n",
    "        return Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4D tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating a tensor of shape (B, 3,32,32) with mean tensor([[59., 78., 62.]]) and covariance \n",
      " tensor([[49.1000, 14.0000, 56.0000],\n",
      "        [14.0000,  4.1000, 16.0000],\n",
      "        [56.0000, 16.0000, 64.1000]]):\n",
      "actual mean and cov: tensor([59.0727, 78.0227, 62.0803]),\n",
      " tensor([[49.8842, 14.2209, 56.8721],\n",
      "        [14.2209,  4.1618, 16.2462],\n",
      "        [56.8721, 16.2462, 65.0648]])\n"
     ]
    }
   ],
   "source": [
    "# Create a batch of 2D images (batch size, channels, height, width)\n",
    "num_features = 3\n",
    "m = torch.randint(10,100,(1,num_features)).float()\n",
    "c = torch.randint(1,10,(1,num_features))\n",
    "cov = c.T@c + 0.1*torch.eye(num_features)\n",
    "\n",
    "print(f'generating a tensor of shape (B, {num_features},32,32) with mean {m} and covariance \\n {cov}:')\n",
    "x = torch.randn(20, num_features, 32, 32).permute(1,0,2,3).reshape(num_features,-1).T\n",
    "L = torch.linalg.cholesky(cov.float())\n",
    "xc= x@L.T + m\n",
    "print(f'actual mean and cov: {xc.mean(0)},\\n {torch.cov(xc.T,correction=0)}')\n",
    "xc = xc.permute(1,0).reshape(num_features,20,32,32).permute(1,0,2,3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0001e+00, -1.7687e-05, -4.7574e-05],\n",
      "        [-1.7687e-05,  1.0002e+00,  2.9081e-04],\n",
      "        [-4.7574e-05,  2.9081e-04,  1.0020e+00]])\n",
      "Functional validation passed!\n"
     ]
    }
   ],
   "source": [
    "# Our custom batch normalization layer\n",
    "bw_layer = BatchWhitening(num_features,momentum=1)\n",
    "\n",
    "# Forward pass\n",
    "x_w = bw_layer(xc)\n",
    "\n",
    "x_w_cov = x_w.permute(1,0,2,3).reshape(x.shape[1],-1).cov()\n",
    "print(x_w_cov)\n",
    "# Check if the outputs are indeed orthonormal\n",
    "assert torch.allclose(x_w_cov, torch.eye(num_features), atol=1e-2), \"The outputs are not close enough!\"\n",
    "\n",
    "print(\"Functional validation passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.is_grad_enabled()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating a tensor of shape (B, 10) with mean tensor([[66., 38., 73., 19., 88., 82., 68., 25., 33., 73.]]) and covariance \n",
      " tensor([[25.1000, 10.0000, 25.0000, 10.0000, 40.0000, 10.0000,  5.0000,  5.0000,\n",
      "         20.0000, 40.0000],\n",
      "        [10.0000,  4.1000, 10.0000,  4.0000, 16.0000,  4.0000,  2.0000,  2.0000,\n",
      "          8.0000, 16.0000],\n",
      "        [25.0000, 10.0000, 25.1000, 10.0000, 40.0000, 10.0000,  5.0000,  5.0000,\n",
      "         20.0000, 40.0000],\n",
      "        [10.0000,  4.0000, 10.0000,  4.1000, 16.0000,  4.0000,  2.0000,  2.0000,\n",
      "          8.0000, 16.0000],\n",
      "        [40.0000, 16.0000, 40.0000, 16.0000, 64.1000, 16.0000,  8.0000,  8.0000,\n",
      "         32.0000, 64.0000],\n",
      "        [10.0000,  4.0000, 10.0000,  4.0000, 16.0000,  4.1000,  2.0000,  2.0000,\n",
      "          8.0000, 16.0000],\n",
      "        [ 5.0000,  2.0000,  5.0000,  2.0000,  8.0000,  2.0000,  1.1000,  1.0000,\n",
      "          4.0000,  8.0000],\n",
      "        [ 5.0000,  2.0000,  5.0000,  2.0000,  8.0000,  2.0000,  1.0000,  1.1000,\n",
      "          4.0000,  8.0000],\n",
      "        [20.0000,  8.0000, 20.0000,  8.0000, 32.0000,  8.0000,  4.0000,  4.0000,\n",
      "         16.1000, 32.0000],\n",
      "        [40.0000, 16.0000, 40.0000, 16.0000, 64.0000, 16.0000,  8.0000,  8.0000,\n",
      "         32.0000, 64.1000]]):\n",
      "actual mean and cov: tensor([65.9919, 37.9985, 72.9887, 18.9943, 87.9902, 81.9979, 67.9955, 24.9946,\n",
      "        32.9931, 72.9875]),\n",
      " tensor([[25.0471,  9.9812, 24.9604,  9.9952, 39.9177,  9.9888,  4.9863,  4.9883,\n",
      "         19.9559, 39.9381],\n",
      "        [ 9.9812,  4.0932,  9.9850,  3.9977, 15.9689,  3.9962,  1.9951,  1.9947,\n",
      "          7.9823, 15.9774],\n",
      "        [24.9604,  9.9850, 25.0698,  9.9974, 39.9332,  9.9939,  4.9898,  4.9915,\n",
      "         19.9655, 39.9554],\n",
      "        [ 9.9952,  3.9977,  9.9974,  4.1035, 15.9906,  4.0008,  1.9975,  1.9989,\n",
      "          7.9945, 15.9985],\n",
      "        [39.9177, 15.9689, 39.9332, 15.9906, 63.9683, 15.9832,  7.9792,  7.9817,\n",
      "         31.9278, 63.9015],\n",
      "        [ 9.9888,  3.9962,  9.9939,  4.0008, 15.9832,  4.1006,  1.9966,  1.9968,\n",
      "          7.9900, 15.9918],\n",
      "        [ 4.9863,  1.9951,  4.9898,  1.9975,  7.9792,  1.9966,  1.0971,  0.9968,\n",
      "          3.9887,  7.9838],\n",
      "        [ 4.9883,  1.9947,  4.9915,  1.9989,  7.9817,  1.9968,  0.9968,  1.0984,\n",
      "          3.9904,  7.9854],\n",
      "        [19.9559,  7.9823, 19.9655,  7.9945, 31.9278,  7.9900,  3.9887,  3.9904,\n",
      "         16.0606, 31.9442],\n",
      "        [39.9383, 15.9775, 39.9554, 15.9985, 63.9015, 15.9918,  7.9838,  7.9854,\n",
      "         31.9442, 64.0338]])\n"
     ]
    }
   ],
   "source": [
    "# Create a batch of vectors (B, num_features)\n",
    "num_features = 10\n",
    "m = torch.randint(10,100,(1,num_features)).float()\n",
    "c = torch.randint(1,10,(1,num_features))\n",
    "cov = c.T@c + 0.1*torch.eye(num_features)\n",
    "\n",
    "print(f'generating a tensor of shape (B, {num_features}) with mean {m} and covariance \\n {cov}:')\n",
    "x = torch.randn(20000, num_features)\n",
    "L = torch.linalg.cholesky(cov.float())\n",
    "xc= x@L.T + m \n",
    "\n",
    "print(f'actual mean and cov: {xc.mean(0)},\\n {torch.cov(xc.T,correction=0)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0000e+00,  5.3830e-06,  4.7240e-05, -7.9326e-06, -5.7434e-05,\n",
      "          2.1321e-06,  6.7980e-06, -1.5218e-06, -2.1695e-06, -1.5783e-05],\n",
      "        [ 5.3841e-06,  9.9998e-01,  3.5401e-05, -6.2590e-06,  5.5552e-04,\n",
      "         -1.7931e-04, -6.6148e-05, -3.5519e-05, -1.2134e-04, -4.0477e-04],\n",
      "        [ 4.7240e-05,  3.5401e-05,  9.9907e-01,  4.9824e-05, -1.6165e-04,\n",
      "         -9.6805e-06, -6.3025e-05,  1.2189e-05, -2.2067e-04,  1.8161e-04],\n",
      "        [-7.9219e-06, -6.2509e-06,  4.9824e-05,  1.0000e+00,  5.2157e-04,\n",
      "         -1.2211e-04,  1.8204e-05,  4.2289e-05, -1.0851e-04, -1.6295e-04],\n",
      "        [-5.7434e-05,  5.5552e-04, -1.6165e-04,  5.2157e-04,  1.0017e+00,\n",
      "         -1.5310e-04, -7.7433e-05, -2.6723e-05, -2.6612e-04, -8.6174e-04],\n",
      "        [ 2.1360e-06, -1.7930e-04, -9.6805e-06, -1.2211e-04, -1.5310e-04,\n",
      "          1.0001e+00, -1.9027e-05, -1.3850e-05,  3.7746e-04,  6.4313e-04],\n",
      "        [ 6.7980e-06, -6.6148e-05, -6.3025e-05,  1.8204e-05, -7.7433e-05,\n",
      "         -1.9027e-05,  9.9991e-01,  2.5108e-05,  8.1434e-05,  4.9194e-05],\n",
      "        [-1.5237e-06, -3.5535e-05,  1.2189e-05,  4.2289e-05, -2.6723e-05,\n",
      "         -1.3850e-05,  2.5108e-05,  9.9991e-01, -5.4112e-06,  3.7063e-04],\n",
      "        [-2.1695e-06, -1.2134e-04, -2.2067e-04, -1.0851e-04, -2.6612e-04,\n",
      "          3.7746e-04,  8.1434e-05, -5.4112e-06,  1.0006e+00,  1.1285e-03],\n",
      "        [-1.5776e-05, -4.0477e-04,  1.8161e-04, -1.6295e-04, -8.6174e-04,\n",
      "          6.4313e-04,  4.9194e-05,  3.7063e-04,  1.1285e-03,  1.0015e+00]])\n"
     ]
    }
   ],
   "source": [
    "# Our custom batch normalization layer\n",
    "bw_layer = BatchWhitening(num_features,momentum=1)\n",
    "\n",
    "# Forward pass\n",
    "x_w = bw_layer(xc)\n",
    "\n",
    "print(torch.cov(x_w.T,correction=0))\n",
    "\n",
    "# Check if the outputs are indeed orthonormal\n",
    "assert torch.allclose(x_w.T.cov(), torch.eye(num_features), atol=1e-2), \"The outputs are not close enough!\"\n",
    "\n",
    "# print(\"Functional validation passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
