{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Whitening Layer\n",
    "The purpose of this notebook is to implement the batch whitening layer.   \n",
    "The implementation is inspired by the implementation of BatchNorm layer from [this reference](https://d2l.ai/chapter_convolutional-modern/batch-norm.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device to use: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print(\"Device to use:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization  \n",
    "Lets start with implementing BatchNorm from scratch and test it on a simple dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm(X, gamma, beta, running_mean, running_var, eps, momentum):\n",
    "    # Use is_grad_enabled to determine whether we are in training mode\n",
    "    assert len(X.shape) in (2, 4)\n",
    "    if len(X.shape) == 2:\n",
    "        shape = (1, X.shape[1])\n",
    "    else:\n",
    "        shape = (1, X.shape[1], 1, 1)\n",
    "\n",
    "    if not torch.is_grad_enabled():\n",
    "        # In prediction mode, use mean and variance obtained by moving average\n",
    "        X_hat = (X - running_mean) / torch.sqrt(running_var + eps)\n",
    "    else:\n",
    "        if len(X.shape) == 2:\n",
    "            # When using a fully connected layer, calculate the mean and\n",
    "            # variance on the feature dimension\n",
    "            mean = X.mean(dim=0)\n",
    "            var = ((X - mean) ** 2).mean(dim=0)\n",
    "        else:\n",
    "            # When using a two-dimensional convolutional layer, calculate the\n",
    "            # mean and variance on the channel dimension (axis=1). Here we\n",
    "            # need to maintain the shape of X, so that the broadcasting\n",
    "            # operation can be carried out later\n",
    "            mean = X.mean(dim=(0, 2, 3), keepdim=True)\n",
    "            var = ((X - mean) ** 2).mean(dim=(0, 2, 3), keepdim=True)\n",
    "        # In training mode, the current mean and variance are used\n",
    "        X_hat = (X - mean) / torch.sqrt(var + eps)\n",
    "        # Update the mean and variance using moving average\n",
    "        running_mean = (1.0 - momentum) * running_mean + momentum * mean\n",
    "        running_var = (1.0 - momentum) * running_var + momentum * var\n",
    "    Y = gamma.view(shape) * X_hat + beta.view(shape)  # Scale and shift\n",
    "    return Y, running_mean.data, running_var.data\n",
    "\n",
    "\n",
    "class BatchNorm(nn.Module):\n",
    "    # num_features: the number of outputs for a fully connected layer or the\n",
    "    # number of output channels for a convolutional layer. num_dims: 2 for a\n",
    "    # fully connected layer and 4 for a convolutional layer\n",
    "    def __init__(self, num_features, num_dims):\n",
    "        super().__init__()\n",
    "        # if num_dims == 2:\n",
    "        #     shape = (1, num_features)\n",
    "        # else:\n",
    "        #     shape = (1, num_features, 1, 1)\n",
    "        shape = num_features\n",
    "        # The scale parameter and the shift parameter (model parameters) are\n",
    "        # initialized to 1 and 0, respectively\n",
    "        self.gamma = nn.Parameter(torch.ones(shape))\n",
    "        self.beta = nn.Parameter(torch.zeros(shape))\n",
    "\n",
    "        # The variables that are not model parameters are initialized to 0 and 1\n",
    "        # self.running_mean = torch.zeros(shape)\n",
    "        # self.running_var = torch.ones(shape)\n",
    "        self.register_buffer('running_mean', torch.zeros(shape))\n",
    "        self.register_buffer('running_var', torch.ones(shape))\n",
    "\n",
    "    def forward(self, X):\n",
    "        # If X is not on the main memory, copy moving_mean and moving_var to\n",
    "        # the device where X is located\n",
    "        if self.running_mean.device != X.device:\n",
    "            self.running_mean = self.running_mean.to(X.device)\n",
    "            self.running_var = self.running_var.to(X.device)\n",
    "        # Save the updated running_mean and moving_var\n",
    "        Y, self.running_mean, self.running_var = batch_norm(\n",
    "            X, self.gamma, self.beta, self.running_mean,\n",
    "            self.running_var, eps=1e-5, momentum=0.1)\n",
    "        return Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm2d(nn.Module):\n",
    "    def __init__(self, num_features, eps=1e-5, momentum=0.1):\n",
    "        super(BatchNorm2d, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        # Learnable parameters\n",
    "        self.gamma = nn.Parameter(torch.ones(num_features))\n",
    "        self.beta = nn.Parameter(torch.zeros(num_features))\n",
    "        # Running mean and variance\n",
    "        self.register_buffer('running_mean', torch.zeros(num_features))\n",
    "        self.register_buffer('running_var', torch.ones(num_features))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            # Calculate mean and variance for the batch\n",
    "            mean = x.mean([0, 2, 3], keepdim=True)\n",
    "            var = x.var([0, 2, 3], keepdim=True, unbiased=False)\n",
    "            # Update running mean and variance\n",
    "            self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * mean\n",
    "            self.running_var = (1 - self.momentum) * self.running_var + self.momentum * var\n",
    "        else:\n",
    "            mean = self.running_mean\n",
    "            var = self.running_var\n",
    "        \n",
    "        # Normalize\n",
    "        x_normalized = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        # Scale and shift\n",
    "        out = self.gamma.view(1, self.num_features, 1, 1) * x_normalized + self.beta.view(1, self.num_features, 1, 1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a batch of 2D images (batch size, channels, height, width)\n",
    "x = torch.randn(20, 10, 50, 50)\n",
    "\n",
    "# Our custom batch normalization layer\n",
    "custom_bn = BatchNorm(num_features=10, num_dims=4)\n",
    "# custom_bn = BatchNorm2d(num_features=10)\n",
    "\n",
    "# PyTorch's built-in batch normalization layer\n",
    "torch_bn = nn.BatchNorm2d(num_features=10)\n",
    "\n",
    "\n",
    "# Copy the parameters from our custom layer to the built-in layer for a fair comparison\n",
    "torch_bn.weight.data = custom_bn.gamma.data.clone()\n",
    "torch_bn.bias.data = custom_bn.beta.data.clone()\n",
    "torch_bn.running_mean = custom_bn.running_mean.clone()\n",
    "torch_bn.running_var = custom_bn.running_var.clone()\n",
    "\n",
    "# Forward pass\n",
    "custom_bn_output = custom_bn(x)\n",
    "torch_bn_output = torch_bn(x)\n",
    "\n",
    "# Check if the outputs are close\n",
    "assert torch.allclose(custom_bn_output, torch_bn_output, atol=1e-5), \"The outputs are not close enough!\"\n",
    "\n",
    "print(\"Functional validation passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.var([0, 2, 3], keepdim=True, unbiased=False).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_bn.training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Whitening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_orthonorm_obsolete(X, gamma, beta, running_mean=None, running_cov=None, eps=1e-5, momentum=0.1):\n",
    "    # Use is_grad_enabled to determine whether we are in training mode\n",
    "    assert len(X.shape) in (2, 4)\n",
    "    n_features = X.shape[1]\n",
    "\n",
    "    if len(X.shape) == 2:\n",
    "        # When using a fully connected layer, calculate the mean and\n",
    "        # variance on the feature dimension\n",
    "        shape = (1, n_features)\n",
    "        mean = X.mean(dim=0)\n",
    "        cov = torch.cov(X.T,correction=0)        \n",
    "        # var = ((X - mean) ** 2).mean(dim=0)\n",
    "    else:\n",
    "        # When using a two-dimensional convolutional layer, calculate the\n",
    "        # mean and covariance on the channel dimension (axis=1). Here we\n",
    "        # need to maintain the shape of X, so that the broadcasting\n",
    "        # operation can be carried out later\n",
    "        shape = (1, n_features, 1, 1)\n",
    "        mean = X.mean(dim=(0, 2, 3))\n",
    "        Xtmp = X.view(X.shape[0],X.shape[1],-1)\n",
    "        Xtmp = Xtmp.permute(1,0,2).reshape(X.shape[1],-1)\n",
    "        cov = torch.cov(Xtmp,correction=0) \n",
    "        # var = ((X - mean) ** 2).mean(dim=(0, 2, 3), keepdim=True)\n",
    "    # In training mode, the current mean and variance are used\n",
    "    # Update the mean and variance using moving average\n",
    "    running_mean = (1.0 - momentum) * running_mean + momentum * mean\n",
    "    running_cov = (1.0 - momentum) * running_cov + momentum * cov\n",
    "    L = torch.linalg.cholesky(running_cov + eps*torch.eye(n_features))\n",
    "    if len(X.shape) == 2:\n",
    "        X_hat = (X-running_mean.view(1,n_features)).T\n",
    "        Y = torch.linalg.solve_triangular(L,X_hat,upper=False).T\n",
    "    else:\n",
    "        X_hat = X-running_mean.view(1,n_features,1,1)\n",
    "        X_hat = X_hat.permute(1,0,2,3).reshape(X.shape[1],-1)\n",
    "        Y = torch.linalg.solve_triangular(L,X_hat,upper=False).reshape(X.shape[1],X.shape[0],X.shape[2],X.shape[3]).permute(1,0,2,3)\n",
    "    # Y = gamma.view(shape) * Y + beta.view(shape)  # Scale and shift\n",
    "    return Y, running_mean.data, running_cov.data\n",
    "\n",
    "def batch_orthonorm(X, gamma, beta, running_mean=None, running_cov=None, eps=1e-5, momentum=0.1):\n",
    "    # Use is_grad_enabled to determine whether we are in training mode\n",
    "    assert len(X.shape) in (2, 4)\n",
    "    n_features = X.shape[1]\n",
    "\n",
    "    if len(X.shape) == 2:\n",
    "        # When using a fully connected layer, calculate the mean and\n",
    "        # variance on the feature dimension\n",
    "        shape = (1, n_features)\n",
    "        mean = X.mean(dim=0)\n",
    "        cov = torch.cov(X.T,correction=0)        \n",
    "        # var = ((X - mean) ** 2).mean(dim=0)\n",
    "    else:\n",
    "        # When using a two-dimensional convolutional layer, calculate the\n",
    "        # mean and covariance on the channel dimension (axis=1). Here we\n",
    "        # need to maintain the shape of X, so that the broadcasting\n",
    "        # operation can be carried out later\n",
    "        shape = (1, n_features, 1, 1)\n",
    "        mean = X.mean(dim=(0, 2, 3))\n",
    "        Xtmp = X.view(X.shape[0],X.shape[1],-1)\n",
    "        Xtmp = Xtmp.permute(1,0,2).reshape(X.shape[1],-1)\n",
    "        cov = torch.cov(Xtmp,correction=0) \n",
    "        # var = ((X - mean) ** 2).mean(dim=(0, 2, 3), keepdim=True)\n",
    "    # In training mode, the current mean and variance are used\n",
    "    # Update the mean and variance using moving average\n",
    "    if torch.is_grad_enabled():\n",
    "        running_mean = (1.0 - momentum) * running_mean + momentum * mean\n",
    "        running_cov = (1.0 - momentum) * running_cov + momentum * cov\n",
    "        L = torch.linalg.cholesky(cov + eps*torch.eye(n_features))\n",
    "        if len(X.shape) == 2:\n",
    "            X_hat = (X-mean.view(1,n_features)).T\n",
    "            Y = torch.linalg.solve_triangular(L,X_hat,upper=False).T\n",
    "        else:\n",
    "            X_hat = X-mean.view(1,n_features,1,1)\n",
    "            X_hat = X_hat.permute(1,0,2,3).reshape(X.shape[1],-1)\n",
    "            Y = torch.linalg.solve_triangular(L,X_hat,upper=False).reshape(X.shape[1],X.shape[0],X.shape[2],X.shape[3]).permute(1,0,2,3)\n",
    "    else:\n",
    "        L = torch.linalg.cholesky(running_cov + eps*torch.eye(n_features))\n",
    "        if len(X.shape) == 2:\n",
    "            X_hat = (X-running_mean.view(1,n_features)).T\n",
    "            Y = torch.linalg.solve_triangular(L,X_hat,upper=False).T\n",
    "        else:\n",
    "            X_hat = X-running_mean.view(1,n_features,1,1)\n",
    "            X_hat = X_hat.permute(1,0,2,3).reshape(X.shape[1],-1)\n",
    "            Y = torch.linalg.solve_triangular(L,X_hat,upper=False).reshape(X.shape[1],X.shape[0],X.shape[2],X.shape[3]).permute(1,0,2,3)\n",
    "    # Y = gamma.view(shape) * Y + beta.view(shape)  # Scale and shift\n",
    "    return Y, running_mean.data, running_cov.data\n",
    "\n",
    "class BatchWhitening(nn.Module):\n",
    "    # num_features: the number of outputs for a fully connected layer or the\n",
    "    # number of output channels for a convolutional layer. num_dims: 2 for a\n",
    "    # fully connected layer and 4 for a convolutional layer\n",
    "    def __init__(self, num_features,momentum=0.1):\n",
    "        super().__init__()\n",
    "        # The scale parameter and the shift parameter (model parameters) are\n",
    "        # initialized to 1 and 0, respectively\n",
    "        self.momentum = momentum\n",
    "        self.gamma = nn.Parameter(torch.ones(num_features))\n",
    "        self.beta = nn.Parameter(torch.zeros(num_features))\n",
    "        # The variables that are not model parameters are initialized to 0 and 1\n",
    "        self.register_buffer('running_mean', torch.zeros(num_features))\n",
    "        self.register_buffer('running_cov', torch.eye(num_features))\n",
    "\n",
    "    def forward(self, X):\n",
    "        # If X is not on the main memory, copy moving_mean and moving_var to\n",
    "        # the device where X is located\n",
    "        if self.running_mean.device != X.device:\n",
    "            self.running_mean = self.running_mean.to(X.device)\n",
    "            self.running_cov = self.running_cov.to(X.device)\n",
    "        # Save the updated running_mean and moving_var\n",
    "        # Y, self.running_mean, self.running_var = batch_orthonorm(\n",
    "        #     X, self.gamma, self.beta, self.running_mean,\n",
    "        #     self.running_cov, eps=1e-5, momentum=0.1)\n",
    "        Y, self.running_mean, self.running_cov = batch_orthonorm(\n",
    "            X, self.gamma, self.beta, self.running_mean,\n",
    "            self.running_cov, eps=1e-5, momentum=self.momentum)\n",
    "\n",
    "        return Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4D tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating a tensor of shape (B, 3,32,32) with mean tensor([[29., 27., 21.]]) and covariance \n",
      " tensor([[64.1000, 64.0000, 40.0000],\n",
      "        [64.0000, 64.1000, 40.0000],\n",
      "        [40.0000, 40.0000, 25.1000]]):\n",
      "actual mean and cov: tensor([29.0015, 27.0027, 20.9997]),\n",
      " tensor([[64.2156, 64.1060, 40.0807],\n",
      "        [64.1060, 64.1925, 40.0733],\n",
      "        [40.0807, 40.0733, 25.1551]])\n"
     ]
    }
   ],
   "source": [
    "# Create a batch of 2D images (batch size, channels, height, width)\n",
    "num_features = 3\n",
    "m = torch.randint(10,100,(1,num_features)).float()\n",
    "c = torch.randint(1,10,(1,num_features))\n",
    "cov = c.T@c + 0.1*torch.eye(num_features)\n",
    "\n",
    "print(f'generating a tensor of shape (B, {num_features},32,32) with mean {m} and covariance \\n {cov}:')\n",
    "x = torch.randn(20, num_features, 32, 32).permute(1,0,2,3).reshape(num_features,-1).T\n",
    "L = torch.linalg.cholesky(cov.float())\n",
    "xc= x@L.T + m\n",
    "print(f'actual mean and cov: {xc.mean(0)},\\n {torch.cov(xc.T,correction=0)}')\n",
    "xc = xc.permute(1,0).reshape(num_features,20,32,32).permute(1,0,2,3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0001e+00, -7.1795e-05, -2.0783e-05],\n",
      "        [-7.1795e-05,  1.0022e+00, -3.2540e-04],\n",
      "        [-2.0783e-05, -3.2540e-04,  1.0007e+00]])\n",
      "Functional validation passed!\n"
     ]
    }
   ],
   "source": [
    "# Our custom batch normalization layer\n",
    "bw_layer = BatchWhitening(num_features,momentum=1)\n",
    "\n",
    "# Forward pass\n",
    "x_w = bw_layer(xc)\n",
    "\n",
    "x_w_cov = x_w.permute(1,0,2,3).reshape(x.shape[1],-1).cov()\n",
    "print(x_w_cov)\n",
    "# Check if the outputs are indeed orthonormal\n",
    "assert torch.allclose(x_w_cov, torch.eye(num_features), atol=1e-2), \"The outputs are not close enough!\"\n",
    "\n",
    "print(\"Functional validation passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating a tensor of shape (B, 10) with mean tensor([[25., 62., 16., 28., 47., 59., 94., 44., 80., 54.]]) and covariance \n",
      " tensor([[81.1000, 27.0000, 63.0000, 36.0000, 63.0000, 18.0000, 27.0000, 18.0000,\n",
      "         81.0000, 63.0000],\n",
      "        [27.0000,  9.1000, 21.0000, 12.0000, 21.0000,  6.0000,  9.0000,  6.0000,\n",
      "         27.0000, 21.0000],\n",
      "        [63.0000, 21.0000, 49.1000, 28.0000, 49.0000, 14.0000, 21.0000, 14.0000,\n",
      "         63.0000, 49.0000],\n",
      "        [36.0000, 12.0000, 28.0000, 16.1000, 28.0000,  8.0000, 12.0000,  8.0000,\n",
      "         36.0000, 28.0000],\n",
      "        [63.0000, 21.0000, 49.0000, 28.0000, 49.1000, 14.0000, 21.0000, 14.0000,\n",
      "         63.0000, 49.0000],\n",
      "        [18.0000,  6.0000, 14.0000,  8.0000, 14.0000,  4.1000,  6.0000,  4.0000,\n",
      "         18.0000, 14.0000],\n",
      "        [27.0000,  9.0000, 21.0000, 12.0000, 21.0000,  6.0000,  9.1000,  6.0000,\n",
      "         27.0000, 21.0000],\n",
      "        [18.0000,  6.0000, 14.0000,  8.0000, 14.0000,  4.0000,  6.0000,  4.1000,\n",
      "         18.0000, 14.0000],\n",
      "        [81.0000, 27.0000, 63.0000, 36.0000, 63.0000, 18.0000, 27.0000, 18.0000,\n",
      "         81.1000, 63.0000],\n",
      "        [63.0000, 21.0000, 49.0000, 28.0000, 49.0000, 14.0000, 21.0000, 14.0000,\n",
      "         63.0000, 49.1000]]):\n",
      "actual mean and cov: tensor([25.0439, 62.0156, 16.0369, 28.0212, 47.0352, 59.0126, 94.0186, 44.0095,\n",
      "        80.0462, 54.0365]),\n",
      " tensor([[80.5909, 26.8487, 62.5849, 35.8006, 62.5860, 17.8627, 26.8312, 17.8938,\n",
      "         80.4405, 62.6129],\n",
      "        [26.8487,  9.0580, 20.8765, 11.9419, 20.8764,  5.9574,  8.9503,  5.9684,\n",
      "         26.8332, 20.8850],\n",
      "        [62.5849, 20.8765, 48.7619, 27.8365, 48.6619, 13.8859, 20.8613, 13.9127,\n",
      "         62.5434, 48.6814],\n",
      "        [35.8005, 11.9419, 27.8365, 16.0230, 27.8377,  7.9435, 11.9336,  7.9583,\n",
      "         35.7776, 27.8483],\n",
      "        [62.5860, 20.8764, 48.6619, 27.8377, 48.7656, 13.8882, 20.8633, 13.9132,\n",
      "         62.5456, 48.6832],\n",
      "        [17.8627,  5.9575, 13.8859,  7.9435, 13.8882,  4.0645,  5.9531,  3.9720,\n",
      "         17.8508, 13.8931],\n",
      "        [26.8312,  8.9503, 20.8613, 11.9336, 20.8633,  5.9531,  9.0465,  5.9654,\n",
      "         26.8145, 20.8720],\n",
      "        [17.8938,  5.9684, 13.9127,  7.9583, 13.9132,  3.9720,  5.9654,  4.0794,\n",
      "         17.8834, 13.9197],\n",
      "        [80.4405, 26.8332, 62.5434, 35.7776, 62.5456, 17.8508, 26.8145, 17.8834,\n",
      "         80.4898, 62.5729],\n",
      "        [62.6128, 20.8850, 48.6814, 27.8483, 48.6832, 13.8931, 20.8720, 13.9197,\n",
      "         62.5729, 48.8039]])\n"
     ]
    }
   ],
   "source": [
    "# Create a batch of vectors (B, num_features)\n",
    "num_features = 10\n",
    "m = torch.randint(10,100,(1,num_features)).float()\n",
    "c = torch.randint(1,10,(1,num_features))\n",
    "cov = c.T@c + 0.1*torch.eye(num_features)\n",
    "\n",
    "print(f'generating a tensor of shape (B, {num_features}) with mean {m} and covariance \\n {cov}:')\n",
    "x = torch.randn(20000, num_features)\n",
    "L = torch.linalg.cholesky(cov.float())\n",
    "xc= x@L.T + m \n",
    "\n",
    "print(f'actual mean and cov: {xc.mean(0)},\\n {torch.cov(xc.T,correction=0)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0000e+00, -3.1479e-05, -1.2375e-04, -1.7883e-05,  6.2787e-05,\n",
      "         -1.2165e-05, -2.6292e-05, -6.3144e-06,  6.5099e-05, -7.6969e-05],\n",
      "        [-3.1467e-05,  1.0001e+00,  1.1378e-03,  3.5838e-05, -8.6736e-04,\n",
      "          4.6297e-05,  2.0276e-04,  1.8911e-04, -4.8607e-04,  6.3275e-04],\n",
      "        [-1.2375e-04,  1.1378e-03,  1.0033e+00,  8.6579e-04, -6.9715e-05,\n",
      "          1.0257e-04,  3.2663e-04,  8.0492e-05, -6.5207e-05,  2.0619e-03],\n",
      "        [-1.7882e-05,  3.5836e-05,  8.6579e-04,  9.9959e-01, -5.7881e-04,\n",
      "          1.5406e-04,  4.0285e-04, -4.8886e-05, -4.8925e-04,  2.9243e-04],\n",
      "        [ 6.2787e-05, -8.6736e-04, -6.9715e-05, -5.7881e-04,  9.9747e-01,\n",
      "          2.1352e-04,  1.9974e-06, -4.2332e-05, -1.8930e-03,  3.2424e-04],\n",
      "        [-1.2162e-05,  4.6294e-05,  1.0257e-04,  1.5406e-04,  2.1352e-04,\n",
      "          1.0000e+00,  2.5533e-04,  1.6552e-04, -5.6447e-04,  5.0011e-04],\n",
      "        [-2.6292e-05,  2.0276e-04,  3.2663e-04,  4.0285e-04,  1.9974e-06,\n",
      "          2.5533e-04,  1.0002e+00,  6.8853e-05,  9.9506e-04,  5.5005e-04],\n",
      "        [-6.3200e-06,  1.8909e-04,  8.0492e-05, -4.8886e-05, -4.2332e-05,\n",
      "          1.6552e-04,  6.8853e-05,  9.9986e-01, -1.1685e-03,  3.9215e-04],\n",
      "        [ 6.5099e-05, -4.8607e-04, -6.5207e-05, -4.8925e-04, -1.8930e-03,\n",
      "         -5.6447e-04,  9.9506e-04, -1.1685e-03,  1.0013e+00, -1.1300e-03],\n",
      "        [-7.6965e-05,  6.3275e-04,  2.0619e-03,  2.9243e-04,  3.2424e-04,\n",
      "          5.0011e-04,  5.5005e-04,  3.9215e-04, -1.1300e-03,  1.0031e+00]])\n"
     ]
    }
   ],
   "source": [
    "# Our custom batch normalization layer\n",
    "bw_layer = BatchWhitening(num_features,momentum=1)\n",
    "\n",
    "# Forward pass\n",
    "x_w = bw_layer(xc)\n",
    "\n",
    "print(torch.cov(x_w.T,correction=0))\n",
    "\n",
    "# Check if the outputs are indeed orthonormal\n",
    "assert torch.allclose(x_w.T.cov(), torch.eye(num_features), atol=1e-2), \"The outputs are not close enough!\"\n",
    "\n",
    "# print(\"Functional validation passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_bn_output.permute(1,0,2,3).reshape(x.shape[1],-1).cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.arange(0, 10)\n",
    "cov = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=torch.randint(1,10,(3,1))\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[25, 15, 35],\n",
       "        [15,  9, 21],\n",
       "        [35, 21, 49]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov = c@c.T\n",
    "cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(20, 10, 50, 50)\n",
    "\n",
    "mean = X.mean(dim=(0, 2, 3))\n",
    "Xtmp = X.view(X.shape[0],X.shape[1],-1)\n",
    "Xtmp = Xtmp.permute(1,0,2).reshape(X.shape[1],-1)\n",
    "cov = torch.cov(Xtmp,correction=0) \n",
    "\n",
    "assert torch.allclose(cov, torch.eye(10), atol=1e-5), \"The outputs are not close enough!\"\n",
    "print(\"Functional validation passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4D input tensor\n",
    "n_features = 10\n",
    "X = torch.randn(20, n_features, 50, 50)\n",
    "\n",
    "shape = n_features\n",
    "gamma = torch.ones(shape)\n",
    "beta = torch.zeros(shape)\n",
    "\n",
    "running_mean = torch.zeros(shape)\n",
    "running_cov = torch.eye(shape)\n",
    "\n",
    "mean = X.mean(dim=(0, 2, 3))\n",
    "Xtmp = X.view(X.shape[0],X.shape[1],-1)\n",
    "Xtmp = Xtmp.permute(1,0,2).reshape(X.shape[1],-1)\n",
    "cov = torch.cov(Xtmp,correction=0) \n",
    "\n",
    "\n",
    "momentum = 0.1 \n",
    "eps = 1e-5\n",
    "running_mean = (1.0 - momentum) * running_mean + momentum * mean\n",
    "running_cov = (1.0 - momentum) * running_cov + momentum * cov\n",
    "\n",
    "L = torch.linalg.cholesky(running_cov + eps*torch.eye(n_features))\n",
    "X_hat = X-running_mean.view(1,n_features,1,1)\n",
    "X_hat = X_hat.permute(1,0,2,3).reshape(X.shape[1],-1)\n",
    "Y = torch.linalg.solve_triangular(L,X_hat,upper=False).reshape(X.shape[1],X.shape[0],X.shape[2],X.shape[3]).permute(1,0,2,3)\n",
    "\n",
    "\n",
    "# assert torch.allclose(cov, torch.eye(10), atol=1e-5), \"The outputs are not close enough!\"\n",
    "# print(\"Functional validation passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D input tensor\n",
    "n_features = 10\n",
    "X = torch.randn(20, n_features)\n",
    "\n",
    "shape = n_features\n",
    "gamma = torch.ones(shape)\n",
    "beta = torch.zeros(shape)\n",
    "\n",
    "running_mean = torch.zeros(shape)\n",
    "running_cov = torch.eye(shape)\n",
    "\n",
    "mean = X.mean(dim=0)\n",
    "cov = torch.cov(X.T,correction=0)\n",
    "\n",
    "momentum = 0.1 \n",
    "eps = 1e-5\n",
    "running_mean = (1.0 - momentum) * running_mean + momentum * mean\n",
    "running_cov = (1.0 - momentum) * running_cov + momentum * cov\n",
    "\n",
    "L = torch.linalg.cholesky(running_cov + eps*torch.eye(n_features))\n",
    "X_hat = X-running_mean.view(1,n_features)\n",
    "X_hat = X_hat.T\n",
    "Y = torch.linalg.solve_triangular(L,X_hat,upper=False).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_orthonorm(X, gamma, beta, running_mean, running_cov, eps, momentum):\n",
    "    # Use is_grad_enabled to determine whether we are in training mode\n",
    "    assert len(X.shape) in (2, 4)\n",
    "    n_features = X.shape[1]\n",
    "\n",
    "    if len(X.shape) == 2:\n",
    "        # When using a fully connected layer, calculate the mean and\n",
    "        # variance on the feature dimension\n",
    "        shape = (1, n_features)\n",
    "        mean = X.mean(dim=0)\n",
    "        cov = torch.cov(X.T,correction=0)        \n",
    "        # var = ((X - mean) ** 2).mean(dim=0)\n",
    "    else:\n",
    "        # When using a two-dimensional convolutional layer, calculate the\n",
    "        # mean and covariance on the channel dimension (axis=1). Here we\n",
    "        # need to maintain the shape of X, so that the broadcasting\n",
    "        # operation can be carried out later\n",
    "        shape = (1, n_features, 1, 1)\n",
    "        mean = X.mean(dim=(0, 2, 3), keepdim=True)\n",
    "        Xtmp = X.view(X.shape[0],X.shape[1],-1)\n",
    "        Xtmp = Xtmp.permute(1,0,2).reshape(X.shape[1],-1)\n",
    "        cov = torch.cov(Xtmp,correction=0) \n",
    "        # var = ((X - mean) ** 2).mean(dim=(0, 2, 3), keepdim=True)\n",
    "    # In training mode, the current mean and variance are used\n",
    "    # Update the mean and variance using moving average\n",
    "    running_mean = (1.0 - momentum) * running_mean + momentum * mean\n",
    "    running_cov = (1.0 - momentum) * running_cov + momentum * cov\n",
    "    L = torch.linalg.cholesky(running_cov + eps*torch.eye(n_features))\n",
    "    if len(X.shape) == 2:\n",
    "        X_hat = (X-running_mean.view(1,n_features)).T\n",
    "        Y = torch.linalg.solve_triangular(L,X_hat,upper=False).T\n",
    "    else:\n",
    "        X_hat = X-running_mean.view(1,n_features,1,1)\n",
    "        X_hat = X_hat.permute(1,0,2,3).reshape(X.shape[1],-1)\n",
    "        Y = torch.linalg.solve_triangular(L,X_hat,upper=False).reshape(X.shape[1],X.shape[0],X.shape[2],X.shape[3]).permute(1,0,2,3)\n",
    "    # Y = gamma.view(shape) * Y + beta.view(shape)  # Scale and shift\n",
    "    return Y, running_mean.data, running_cov.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
